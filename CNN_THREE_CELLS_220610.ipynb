{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_THREE_CELLS_220610.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5lYWA70f4jEFEdBQTo2aO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jesus-anaya/ENSAYO/blob/master/CNN_THREE_CELLS_220610.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJu02OG7qphJ"
      },
      "outputs": [],
      "source": [
        "#TO RUN IN COLAB, 3 CELLS NEEDED!\n",
        "#usar cuenta: jesus.anaya.co para entrar a https://colab.research.google.com/\n",
        "#D:\\disco_D\\anaya\\Teledeteccion\\CNN_NeuralNetworks\n",
        "#last update by janaya 220610\n",
        "\n",
        "\n",
        "#\"\"\"\n",
        "#(1/3)\n",
        "#Supporting script for the medium post titled:\n",
        "#'Is CNN equally shiny on mid-resolution satellite data?'\n",
        "#available at https://medium.com/p/9e24e68f0c08\n",
        "#Author: Pratyush Tripathy\n",
        "#Date: 29 May, 2021\n",
        "#Following package versions were used:\n",
        "#numpy - 1.17.2\n",
        "#sklearn - 0.22.1\n",
        "#pyrsgis - 0.3.9\n",
        "#tensorflow - 2.0.0\n",
        "#\"\"\"\n",
        "\n",
        "#Go to CELL 1 to ensure enough RAM\n",
        "\n",
        "\n",
        "#You need lot of RAM. Increase RAM (DEPRECATED) https://www.youtube.com/watch?v=MHTsS0XEx8E\n",
        "## 1.Copy and Paste the link below to get a new CO page, 2.Save a copy in drive 3. Conectar (check RAM>25gb), 4. Insert a new code cell and go to #CELL 2\n",
        "\n",
        "#Using this link (DEPRECATED)\n",
        "#https://colab.research.google.com/drive/1GqZu6zmCy2vMNMZqO78DDuHvwv_9vJcp?usp=sharing\n",
        "\n",
        "\n",
        "# CELL 1\n",
        "#more CPU AND RAM: the following link can also increase GPU to 25GB (use the following link to increase RAM)\n",
        "## 1.Copy and Paste the link below in the browser to get a new google CO page, 2.Save a copy in drive 3. RUN and Conectar (check RAM>25gb)\n",
        "#https://colab.research.google.com/drive/1mx2SPcWU9UxUDUJfBbatLzpp8LIhmr0i?usp=sharing\n",
        "#! lscpu # use this command to confirm 4 cores & check in connect the 25GB RAM\n",
        "\n",
        "#this web page has the directions to the code\n",
        "#https://towardsdatascience.com/is-cnn-equally-shiny-on-mid-resolution-satellite-data-9e24e68f0c08\n",
        "\n",
        "#https://github.com/PratyushTripathy/Landsat-Classification-Using-Convolution-Neural-Network\n",
        "\n",
        "\n",
        "#This is a video about tensor flow\n",
        "#https://www.youtube.com/watch?v=tPYj3fFJGjk\n",
        "\n",
        "# Copy and Paste the code below in a new cell before CELL 3\n",
        "\n",
        "#CELL 2\n",
        "# Select and copy and run all the code until #CELL 3\n",
        "\n",
        "! lscpu\n",
        "\n",
        "!pip install tensorflow==2.0.0\n",
        "!pip install tensorflow-gpu==2.0.0\n",
        "!pip install h5py==2.10.0\n",
        "#!pip install keras==2.3.0\n",
        "!pip install pyrsgis==0.3.9\n",
        "\n",
        "\n",
        "import os, math, random, glob, time\n",
        "random.seed(2)\n",
        "import numpy as np\n",
        "from pyrsgis import raster\n",
        "from pyrsgis.ml import imageChipsFromFile\n",
        "from sklearn.utils import resample\n",
        "\n",
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)\n",
        "print(tf.version)\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "!pip list | grep tensorflow\n",
        "!pip list | grep tensorflow-gpu\n",
        "!pip list | grep Keras\n",
        "!pip list | grep h5py\n",
        "!pip list | grep tensorboard\n",
        "!pip list | grep numpy\n",
        "!pip list | grep sklearn\n",
        "!pip list | grep pyrsgis\n",
        "!python -V\n",
        "#print(sklearn.__version__)\n",
        "print(keras.__version__)\n",
        "\n",
        "### PART - A: CREATING AND STORING IMAGE CHIPS AS NUMPY ARRAYS  ###\n",
        "\n",
        "# View the working path\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        " \n",
        "#print(os.getcwd())\n",
        "\n",
        "#path = \"/content/gdrive/My Drive/NeuralNetworks\"\n",
        "\n",
        "# define the file names, size of these two files (rows, columns) MUST be equal\n",
        "feature_file = '/content/gdrive/MyDrive/NeuralNetworks/B2B3B4B8B11B12_10M_cl_3.TIF'\n",
        "label_file = '/content/gdrive/MyDrive/NeuralNetworks/AQ_32bit_ds_1.tif'\n",
        "\n",
        "os.chdir(\"/content/gdrive/MyDrive/NeuralNetworks/TDS_CNN\")\n",
        "\n",
        "!pwd\n",
        "!ls   \n",
        "\n",
        "# create feature chips using pyrsgis\n",
        "features = imageChipsFromFile(feature_file, x_size=5, y_size=5)# it uses lot of RAM, originally x_size=11, y_size=11\n",
        "\n",
        "\"\"\" Update: 29 May 2021\n",
        "Since I added this code chunk later, I wanted to make least \n",
        "possible changes in the remaining sections. The below line changes\n",
        "the index of the channels. This will be undone at a later stage.\n",
        "\"\"\"\n",
        "features = np.rollaxis(features, 3, 1)\n",
        "\n",
        "# read the label file and reshape it\n",
        "ds, labels = raster.read(label_file)\n",
        "labels = labels.flatten()\n",
        "\n",
        "#\n",
        "#code for reading and storing image...\n",
        "#\n",
        "\n",
        "# check for irrelevant values (we are interested in 1s and non-1s)\n",
        "labels = (labels == 1).astype(int)\n",
        "\n",
        "# print basic details\n",
        "print('Input features shape:', features.shape)\n",
        "print('Input labels shape:', labels.shape)\n",
        "print('Values in input features, min: %d & max: %d' % (features.min(), features.max()))\n",
        "print('Values in input labels, min: %d & max: %d' % (labels.min(), labels.max()))\n",
        "\n",
        "# Go up one directory\n",
        "os.chdir(\"/content/gdrive/MyDrive/NeuralNetworks/TDS_CNN\")\n",
        "!pwd\n",
        "\n",
        "# Save the arrays as .npy files\n",
        "np.save('CNN_7by7_features.npy', features) # uses lot of RAM, bit depth matters.\n",
        "np.save('CNN_7by7_labels.npy', labels)\n",
        "print('Arrays saved at location %s' % (os.getcwd()))\n",
        "!ls\n",
        "\n",
        "#\"\"\"\"\n",
        "#(2/3)\n",
        "import os, math, random, glob, time\n",
        "random.seed(2)\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import resample\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load arrays from .npy files\n",
        "os.chdir(\"/content/gdrive/MyDrive/NeuralNetworks/TDS_CNN\")\n",
        "features = np.load('CNN_7by7_features.npy') # uses lot LOT! of RAM... more than 25GB\n",
        "labels = np.load('CNN_7by7_labels.npy')\n",
        "\n",
        "# Separate and balance the classes\n",
        "built_features = features[labels==1]\n",
        "built_labels = labels[labels==1]\n",
        "\n",
        "unbuilt_features = features[labels==0]\n",
        "unbuilt_labels = labels[labels==0]\n",
        "\n",
        "print('Number of records in each class:')\n",
        "print('Built: %d, Unbuilt: %d' % (built_labels.shape[0], unbuilt_labels.shape[0]))\n",
        "\n",
        "\n",
        "# Downsample the majority class\n",
        "unbuilt_features = resample(unbuilt_features,\n",
        "                            replace = False, # sample without replacement\n",
        "                            n_samples = built_features.shape[0], # match minority n\n",
        "                            random_state = 2)\n",
        "\n",
        "unbuilt_labels = resample(unbuilt_labels,\n",
        "                          replace = False, # sample without replacement\n",
        "                          n_samples = built_features.shape[0], # match minority n\n",
        "                          random_state = 2)\n",
        "\n",
        "print('Number of records in balanced classes:')\n",
        "print('Built: %d, Unbuilt: %d' % (built_labels.shape[0], unbuilt_labels.shape[0]))\n",
        "\n",
        "# Combine the balanced features\n",
        "features = np.concatenate((built_features, unbuilt_features), axis=0)\n",
        "labels = np.concatenate((built_labels, unbuilt_labels), axis=0)\n",
        "\n",
        "# Normalise the features\n",
        "features = features / 255.0\n",
        "print('New values in input features, min: %d & max: %d' % (features.min(), features.max()))\n",
        "\n",
        "\n",
        "\n",
        "# Define the function to split features and labels\n",
        "def train_test_split(features, labels, trainProp=0.6):\n",
        "    dataSize = features.shape[0]\n",
        "    sliceIndex = int(dataSize*trainProp)\n",
        "    randIndex = np.arange(dataSize)\n",
        "    random.shuffle(randIndex)\n",
        "    train_x = features[[randIndex[:sliceIndex]], :, :, :][0]\n",
        "    test_x = features[[randIndex[sliceIndex:]], :, :, :][0]\n",
        "    train_y = labels[randIndex[:sliceIndex]]\n",
        "    test_y = labels[randIndex[sliceIndex:]]\n",
        "    return(train_x, train_y, test_x, test_y)\n",
        "  \n",
        "# Call the function to split the data\n",
        "train_x, train_y, test_x, test_y = train_test_split(features, labels)\n",
        "\n",
        "#\"\"\" Update: 29 May 2021\n",
        "#Transpose the features to channel last format.\n",
        "#If you have commented out the rollaxis line in the \n",
        "#first place. You can comment the following two lines too.\n",
        "#\"\"\"\n",
        "\n",
        "# Transpose the features to channel last format\n",
        "train_x = tf.transpose(train_x, [0, 2, 3, 1])\n",
        "test_x = tf.transpose(test_x, [0, 2, 3, 1])\n",
        "\n",
        "print('Reshaped split features:', train_x.shape, test_x.shape)\n",
        "print('Split labels:', train_y.shape, test_y.shape)\n",
        "_, rowSize, colSize, nBands = train_x.shape\n",
        "\n",
        "# Create a model\n",
        "model = keras.Sequential()\n",
        "model.add(Conv2D(32, kernel_size=1, padding='valid', activation='relu', input_shape=(rowSize, colSize, nBands)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(48, kernel_size=1, padding='valid', activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Run the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer= 'rmsprop',metrics=['accuracy'])\n",
        "history = model.fit(train_x, train_y, epochs=1)# change to 10 epochs when the code works.\n",
        "\n",
        "# Predict for test data \n",
        "yTestPredicted = model.predict(test_x)\n",
        "yTestPredicted = yTestPredicted[:,1]\n",
        "\n",
        "# Calculate and display the error metrics\n",
        "yTestPredicted = (yTestPredicted>0.5).astype(int)\n",
        "cMatrix = confusion_matrix(test_y, yTestPredicted)\n",
        "pScore = precision_score(test_y, yTestPredicted)\n",
        "rScore = recall_score(test_y, yTestPredicted)\n",
        "fScore = f1_score(test_y, yTestPredicted)\n",
        "\n",
        "print(\"Confusion matrix:\\n\", cMatrix)\n",
        "print(\"\\nP-Score: %.3f, R-Score: %.3f, F-Score: %.3f\" % (pScore, rScore, fScore))\n",
        "\n",
        "# Save the model inside a folder to use later\n",
        "if not os.path.exists(os.path.join(os.getcwd(), 'trained_models')):\n",
        "     os.mkdir(os.path.join(os.getcwd(), 'trained_models'))\n",
        "\n",
        "\n",
        "model.save('trained_models/220428_CNN_AQ_PScore%.3f_RScore%.3f_FScore%.3f.h5' % (pScore, rScore, fScore))\n",
        "\n",
        "#Find this new model and replace the name in the \"model\" variable.\n",
        "\n",
        "#\"\"\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "# CELL 3\n",
        "#(3/3)\n",
        "\n",
        "import os, math, random\n",
        "random.seed(2)\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from pyrsgis import raster\n",
        "import glob, time\n",
        "from pyrsgis.ml import imageChipsFromArray\n",
        "\n",
        "!pwd\n",
        "!ls   \n",
        "os.chdir(\"/content/gdrive/MyDrive/NeuralNetworks\")\n",
        "\n",
        "# Load the saved model\n",
        "# note that this model was built in step 2/2, it must be manually updated here.\n",
        "#model = tf.keras.models.load_model('/content/gdrive/MyDrive/NeuralNetworks/TDS_CNN/trained_models/200415_CNN_Builtup_PScore0.950_RScore0.919_FScore0.934.h5')\n",
        "model = tf.keras.models.load_model('/content/gdrive/MyDrive/NeuralNetworks/TDS_CNN/trained_models/220428_CNN_AQ_PScore0.946_RScore0.999_FScore0.972.h5')\n",
        "!ls\n",
        "\n",
        "# Load a new multispectral image\n",
        "ds, featuresNewImage = raster.read('/content/gdrive/MyDrive/NeuralNetworks/B2B3B4B8B11B12_10M_cl_cl_cl.TIF')\n",
        "outFile = 'AQ_CNN_predicted_7by7.tif'\n",
        "\n",
        "\n",
        "# Generate image chips in the back-end, the size of the file can be different but it might run out of memory.\n",
        "def CNNdataGenerator(mxBands, kSize):\n",
        "    mxBands = mxBands / 255.0\n",
        "    nBands, rows, cols = mxBands.shape\n",
        "    margin = math.floor(kSize/2)\n",
        "    mxBands = np.pad(mxBands, margin, mode='constant')[margin:-margin, :, :]\n",
        "\n",
        "    features = np.empty((rows*cols, kSize, kSize, nBands))\n",
        "\n",
        "    n = 0\n",
        "    for row in range(margin, rows+margin):\n",
        "        for col in range(margin, cols+margin):\n",
        "            feat = mxBands[:, row-margin:row+margin+1, col-margin:col+margin+1]\n",
        "\n",
        "            b1, b2, b3, b4, b5, b6 = feat\n",
        "            feat = np.dstack((b1, b2, b3, b4, b5, b6))\n",
        "\n",
        "            features[n, :, :, :] = feat\n",
        "            n += 1\n",
        "            \n",
        "    return(features)\n",
        "\n",
        "# Call the function to generate features tensor\n",
        "new_features = CNNdataGenerator(featuresNewImage, kSize=5) # lo modifiqu√© a 5 basado en lo que hice arriba\n",
        "print('Shape of the new features', new_features.shape)\n",
        "\n",
        "# Predict new data and export the probability raster\n",
        "newPredicted = model.predict(new_features)\n",
        "newPredicted = newPredicted[:,1]\n",
        "\n",
        "prediction = np.reshape(newPredicted, (ds.RasterYSize, ds.RasterXSize))\n",
        "raster.export(prediction, ds, filename=outFile, dtype='float')\n",
        "\n",
        "plt.imshow(prediction)\n",
        "plt.show() "
      ]
    }
  ]
}